{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually Set configurations\n",
    "EMBDEDDING_ENDPOINT=\"https://internaoai.cognitiveservices.azure.com/\"\n",
    "EMBEDDING_KEY=\"c8693a49f46f425ca226498c216ab4a7\"\n",
    "EMBEDDING_MODEL_NAME=\"text-embedding-ada-002\"\n",
    "EMBEDDING_VERSION=\"2023-05-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Configurations from environmental variables.\n",
    "EMBDEDDING_ENDPOINT=os.getenv(\"EMBDEDDING_ENDPOINT\")\n",
    "EMBEDDING_KEY=os.getenv(\"KEY\")\n",
    "EMBEDDING_MODEL_NAME=os.getenv(\"MODEL_NAME\")\n",
    "EMBEDDING_VERSION=os.getenv(\"VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize OpenAI Client\n",
    "client = AzureOpenAI(\n",
    "  api_key = EMBEDDING_KEY,  \n",
    "  api_version = EMBEDDING_VERSION,\n",
    "  azure_endpoint=EMBDEDDING_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to connect to embedding model and get embeddings for a given word(s)\n",
    "def generate_embeddings(word):\n",
    "    response = client.embeddings.create(\n",
    "                    input = word,\n",
    "                    model= EMBEDDING_MODEL_NAME\n",
    "                )\n",
    "    response = json.loads(response.model_dump_json())\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "    # print(response.model_dump_json(indent=2))\n",
    "    # print(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot visualizations (heatmaps, historgrams) for embeddings.\n",
    "def plot_embedding(embedding):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Similarity metrics\n",
    "def compute_similarity(vec1,vec2):\n",
    "    similarity_score = cosine_similarity(vec1,vec2)\n",
    "    print(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70807604]]\n"
     ]
    }
   ],
   "source": [
    "# Club them all togehterking becomes emperor\n",
    "word = \"There lived a certain main in Russia long ago who was big and strong with this eyes of flaming gold\"\n",
    "X = list(generate_embeddings(word=word))\n",
    "vec1 = np.array(X).reshape(1,-1)\n",
    "word = \"Three tier architecture refers to Web Tier, Middle Tier and backend\"\n",
    "Y = list(generate_embeddings(word=word))\n",
    "vec2 = np.array(Y).reshape(1,-1)\n",
    "compute_similarity(vec1,vec2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
